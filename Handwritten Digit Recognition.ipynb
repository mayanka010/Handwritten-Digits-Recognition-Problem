{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANDWRITTEN DIGIT RECOGNITION\n",
    "#### In this project, I have used MNIST Handwritten images dataset which is widely used for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Importing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing various libraries like pandas for operations on dataframes.\n",
    "# numpy for working with numpy arrays and \n",
    "# matplotlib for plotting images\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframe by importing the dataset(csv file) with the pandas\n",
    "data = pd.read_csv(\"mnist_train_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  ...    0.608  0.609  \\\n",
       "0           0  0  0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1           1  4  0    0    0    0    0    0    0    0  ...        0      0   \n",
       "2           2  1  0    0    0    0    0    0    0    0  ...        0      0   \n",
       "3           3  9  0    0    0    0    0    0    0    0  ...        0      0   \n",
       "4           4  2  0    0    0    0    0    0    0    0  ...        0      0   \n",
       "\n",
       "   0.610  0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first five rows of our dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3999.50000</td>\n",
       "      <td>4.444250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174125</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.070875</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>0.042125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>2.889106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.539846</td>\n",
       "      <td>4.082798</td>\n",
       "      <td>3.710670</td>\n",
       "      <td>2.333601</td>\n",
       "      <td>2.290307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1999.75000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3999.50000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5999.25000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7999.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            5       0     0.1     0.2     0.3     0.4  \\\n",
       "count  8000.00000  8000.000000  8000.0  8000.0  8000.0  8000.0  8000.0   \n",
       "mean   3999.50000     4.444250     0.0     0.0     0.0     0.0     0.0   \n",
       "std    2309.54541     2.889106     0.0     0.0     0.0     0.0     0.0   \n",
       "min       0.00000     0.000000     0.0     0.0     0.0     0.0     0.0   \n",
       "25%    1999.75000     2.000000     0.0     0.0     0.0     0.0     0.0   \n",
       "50%    3999.50000     4.000000     0.0     0.0     0.0     0.0     0.0   \n",
       "75%    5999.25000     7.000000     0.0     0.0     0.0     0.0     0.0   \n",
       "max    7999.00000     9.000000     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "          0.5     0.6     0.7   ...          0.608        0.609        0.610  \\\n",
       "count  8000.0  8000.0  8000.0   ...    8000.000000  8000.000000  8000.000000   \n",
       "mean      0.0     0.0     0.0   ...       0.174125     0.115500     0.070875   \n",
       "std       0.0     0.0     0.0   ...       5.539846     4.082798     3.710670   \n",
       "min       0.0     0.0     0.0   ...       0.000000     0.000000     0.000000   \n",
       "25%       0.0     0.0     0.0   ...       0.000000     0.000000     0.000000   \n",
       "50%       0.0     0.0     0.0   ...       0.000000     0.000000     0.000000   \n",
       "75%       0.0     0.0     0.0   ...       0.000000     0.000000     0.000000   \n",
       "max       0.0     0.0     0.0   ...     254.000000   254.000000   253.000000   \n",
       "\n",
       "             0.611        0.612   0.613   0.614   0.615   0.616   0.617  \n",
       "count  8000.000000  8000.000000  8000.0  8000.0  8000.0  8000.0  8000.0  \n",
       "mean      0.043125     0.042125     0.0     0.0     0.0     0.0     0.0  \n",
       "std       2.333601     2.290307     0.0     0.0     0.0     0.0     0.0  \n",
       "min       0.000000     0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "25%       0.000000     0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "50%       0.000000     0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "75%       0.000000     0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "max     187.000000   154.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[8 rows x 786 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing the statistics of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Columns: 786 entries, Unnamed: 0 to 0.617\n",
      "dtypes: int64(786)\n",
      "memory usage: 48.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Printing the information about the columns of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the datatype of the data\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataframe in numpy arrays as we need it in so form while fitting th model.\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again checking the datatype of the data\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into dependent and independent variables(target variable)\n",
    "X = data[:,2:]\n",
    "y = data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the dependent variable\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, ..., 5, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the independent variable\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making variable to plot some number\n",
    "img = X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of img variable\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the variable for plotting image\n",
    "img = img.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ec5808e10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20ec59b54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLotting image using matplotlib\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "### I have used the following algorithms to making the model \n",
    "* KNN (K Nearest Neighbors)\n",
    "* Logistic Regression\n",
    "* Naive Baye's\n",
    "* Artificial Neural Networks(Multi Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNN from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making object of KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model fitting \n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9445895522388059"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy on the train data\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9371212121212121"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy on test data\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 4, 8, 0, 8, 2, 2, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the starting 10 values of test data\n",
    "knn.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 4, 8, 0, 8, 2, 2, 4, 8], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the starting actual 10 values of test data \n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing Logistic Regression for sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making object of Logistic Regression\n",
    "lreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fitting\n",
    "lreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998134328358209"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy on train data\n",
    "lreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371212121212122"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy on test data\n",
    "lreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 4, 8, 0, 8, 2, 2, 4, 8], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the values\n",
    "lreg.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 4, 8, 0, 8, 2, 2, 4, 8], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the actual values\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing Naive Bayes from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the object\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fitting\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842723880597015"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy on train data\n",
    "nb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8287878787878787"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy in test data\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks (Multi Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sequential model, Dense Layer and loss function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing One Hot Encoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making object of one hot encoder\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming train target variable into one hot encoding\n",
    "y_train = ohe.fit_transform(y_train.reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming test target variable into one hot encoding\n",
    "y_test = ohe.fit_transform(y_test.reshape(-1,1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Layers \n",
    "layer_1 = Dense(100, activation=\"tanh\", input_shape = [X.shape[1]]) # First Hidden Layer\n",
    "layer_2 = Dense(50, activation=\"tanh\")                              # Second Hidden Layer\n",
    "out = Dense(y_train.shape[1], activation=\"softmax\")                 # Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 84,060\n",
      "Trainable params: 84,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Making Neural Network\n",
    "model = Sequential()  # Model Building\n",
    "model.add(layer_1)    # Adding Layers\n",
    "model.add(layer_2)\n",
    "model.add(out)\n",
    "model.summary()       # Generating Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5360/5360 [==============================] - 2s 374us/step - loss: 1.5249 - acc: 0.5183\n",
      "Epoch 2/40\n",
      "5360/5360 [==============================] - 0s 85us/step - loss: 0.8122 - acc: 0.7728\n",
      "Epoch 3/40\n",
      "5360/5360 [==============================] - 0s 70us/step - loss: 0.6162 - acc: 0.8256\n",
      "Epoch 4/40\n",
      "5360/5360 [==============================] - 0s 90us/step - loss: 0.5205 - acc: 0.8496\n",
      "Epoch 5/40\n",
      "5360/5360 [==============================] - 0s 92us/step - loss: 0.4716 - acc: 0.8672\n",
      "Epoch 6/40\n",
      "5360/5360 [==============================] - 1s 114us/step - loss: 0.4559 - acc: 0.8646 0s - loss: 0.4533 - acc: 0.86\n",
      "Epoch 7/40\n",
      "5360/5360 [==============================] - 0s 81us/step - loss: 0.4511 - acc: 0.8705\n",
      "Epoch 8/40\n",
      "5360/5360 [==============================] - 0s 81us/step - loss: 0.4165 - acc: 0.8718\n",
      "Epoch 9/40\n",
      "5360/5360 [==============================] - 0s 75us/step - loss: 0.4099 - acc: 0.8744\n",
      "Epoch 10/40\n",
      "5360/5360 [==============================] - 0s 85us/step - loss: 0.4008 - acc: 0.8763\n",
      "Epoch 11/40\n",
      "5360/5360 [==============================] - 0s 74us/step - loss: 0.3825 - acc: 0.8840\n",
      "Epoch 12/40\n",
      "5360/5360 [==============================] - 0s 81us/step - loss: 0.3890 - acc: 0.8817\n",
      "Epoch 13/40\n",
      "5360/5360 [==============================] - 0s 74us/step - loss: 0.3635 - acc: 0.8884\n",
      "Epoch 14/40\n",
      "5360/5360 [==============================] - 0s 71us/step - loss: 0.3473 - acc: 0.8929\n",
      "Epoch 15/40\n",
      "5360/5360 [==============================] - 0s 89us/step - loss: 0.3394 - acc: 0.8959\n",
      "Epoch 16/40\n",
      "5360/5360 [==============================] - 1s 95us/step - loss: 0.3427 - acc: 0.8961\n",
      "Epoch 17/40\n",
      "5360/5360 [==============================] - 1s 97us/step - loss: 0.3429 - acc: 0.8950\n",
      "Epoch 18/40\n",
      "5360/5360 [==============================] - 0s 81us/step - loss: 0.3128 - acc: 0.9080\n",
      "Epoch 19/40\n",
      "5360/5360 [==============================] - 0s 90us/step - loss: 0.3222 - acc: 0.8974\n",
      "Epoch 20/40\n",
      "5360/5360 [==============================] - 1s 100us/step - loss: 0.3062 - acc: 0.9041\n",
      "Epoch 21/40\n",
      "5360/5360 [==============================] - 1s 120us/step - loss: 0.3397 - acc: 0.8948\n",
      "Epoch 22/40\n",
      "5360/5360 [==============================] - 0s 91us/step - loss: 0.3408 - acc: 0.8918\n",
      "Epoch 23/40\n",
      "5360/5360 [==============================] - 1s 100us/step - loss: 0.3129 - acc: 0.9024\n",
      "Epoch 24/40\n",
      "5360/5360 [==============================] - 0s 83us/step - loss: 0.2977 - acc: 0.9054\n",
      "Epoch 25/40\n",
      "5360/5360 [==============================] - 0s 82us/step - loss: 0.3060 - acc: 0.9063\n",
      "Epoch 26/40\n",
      "5360/5360 [==============================] - 0s 73us/step - loss: 0.2936 - acc: 0.9086\n",
      "Epoch 27/40\n",
      "5360/5360 [==============================] - 0s 74us/step - loss: 0.3299 - acc: 0.8976\n",
      "Epoch 28/40\n",
      "5360/5360 [==============================] - 0s 76us/step - loss: 0.3017 - acc: 0.9110\n",
      "Epoch 29/40\n",
      "5360/5360 [==============================] - 0s 87us/step - loss: 0.2812 - acc: 0.9142\n",
      "Epoch 30/40\n",
      "5360/5360 [==============================] - 0s 77us/step - loss: 0.2807 - acc: 0.9129\n",
      "Epoch 31/40\n",
      "5360/5360 [==============================] - 1s 106us/step - loss: 0.2732 - acc: 0.9138\n",
      "Epoch 32/40\n",
      "5360/5360 [==============================] - 0s 76us/step - loss: 0.2637 - acc: 0.9149\n",
      "Epoch 33/40\n",
      "5360/5360 [==============================] - 0s 74us/step - loss: 0.2448 - acc: 0.9248\n",
      "Epoch 34/40\n",
      "5360/5360 [==============================] - 0s 75us/step - loss: 0.2516 - acc: 0.9241\n",
      "Epoch 35/40\n",
      "5360/5360 [==============================] - 0s 76us/step - loss: 0.2785 - acc: 0.9091\n",
      "Epoch 36/40\n",
      "5360/5360 [==============================] - 0s 85us/step - loss: 0.2695 - acc: 0.9119\n",
      "Epoch 37/40\n",
      "5360/5360 [==============================] - 0s 88us/step - loss: 0.2589 - acc: 0.9172\n",
      "Epoch 38/40\n",
      "5360/5360 [==============================] - 0s 92us/step - loss: 0.2609 - acc: 0.9147\n",
      "Epoch 39/40\n",
      "5360/5360 [==============================] - 0s 80us/step - loss: 0.2612 - acc: 0.9132\n",
      "Epoch 40/40\n",
      "5360/5360 [==============================] - 0s 71us/step - loss: 0.2531 - acc: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ec0ecaa58>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fitting\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 0s 110us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3505538862763029, 0.8931818181818182]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the accuracy and losses of on test data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the first value\n",
    "np.argmax(model.predict(X_test[:1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting actual first value\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy by different algorithms\n",
    "* KNN - 93.71 %\n",
    "* Logistic Regression - 83.71 %\n",
    "* Naive Bayes - 82.87 %\n",
    "* MLP - 89.31 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
